
import os
#from shutil import copyfile
from argparse import Namespace
import torch
import torch.nn as nn
from torch.nn.functional import interpolate
from tqdm import tqdm
from loguru import logger
import matplotlib.pyplot as plt

# sys.path.append(os.path.join(os.path.abspath(os.path.dirname(__file__)), ".."))  # uncomment if opening form other dir

from config import get_arguments, post_config
from mario.level_utils import one_hot_to_ascii_level, group_to_token, token_to_group, read_level
from mario.level_image_gen import LevelImageGen as MarioLevelGen
from mariokart.special_mariokart_downsampling import special_mariokart_downsampling
from mariokart.level_image_gen import LevelImageGen as MariokartLevelGen
from mario.tokens import REPLACE_TOKENS as MARIO_REPLACE_TOKENS
from mariokart.tokens import REPLACE_TOKENS as MARIOKART_REPLACE_TOKENS
from mario.tokens import TOKEN_GROUPS as MARIO_TOKEN_GROUPS
from mariokart.tokens import TOKEN_GROUPS as MARIOKART_TOKEN_GROUPS
from mario.special_mario_downsampling import special_mario_downsampling
from generate_noise import generate_spatial_noise
from models import load_trained_pyramid


import numpy as np
import torch

from ribs.archives import GridArchive
from ribs.emitters import OptimizingEmitter
from ribs.optimizers import Optimizer

from evaluate import platform_test


#load the generator and discriminator
#load the weights
#

def gen_samples(generators, noise_maps, reals, noise_amplitudes, in_vecs, device, scale_v=1.0, scale_h=1.0,
                     current_scale=0, gen_start_scale=0):
    """
    Generate samples given a pretrained TOAD-GAN (generators, noise_maps, reals, noise_amplitudes).
    Uses namespace "opt" that needs to be parsed.
    "in_s" can be used as a starting image in any scale set with "current_scale".
    "gen_start_scale" sets the scale generation is to be started in.
    "num_samples" is the number of different samples to be generated.

    "in_vecs" is a set of noise vectors to generate samples from
    """

    # Holds images generated in current scale
    images_cur = []
    token_list = ['!', '#', '-', '1', '@', 'C', 'S', 'U', 'X', 'g', 'k', 't']
    num_layer = 3

    # Main sampling loop
    for G, Z_opt, noise_amp in zip(generators, noise_maps, noise_amplitudes):

        if current_scale >= len(generators):
            break  # if we do not start at current_scale=0 we need this

        logger.info("Generating samples at scale {}", current_scale)

        # Padding (should be chosen according to what was trained with)
        n_pad = int(1*num_layer)
        m = nn.ZeroPad2d(int(n_pad))  # pad with zeros
        
        # Calculate shapes to generate
        ##MARIA: DO WE NEED THIS?
        if 0 < gen_start_scale <= current_scale:  # Special case! Can have a wildly different shape through in_s
            scale_v = in_s.shape[-2] / (noise_maps[gen_start_scale-1].shape[-2] - n_pad * 2)
            scale_h = in_s.shape[-1] / (noise_maps[gen_start_scale-1].shape[-1] - n_pad * 2)
            nzx = (Z_opt.shape[-2] - n_pad * 2) * scale_v
            nzy = (Z_opt.shape[-1] - n_pad * 2) * scale_h
        else:
            nzx = (Z_opt.shape[-2] - n_pad * 2) * scale_v
            nzy = (Z_opt.shape[-1] - n_pad * 2) * scale_h

        # Save list of images of previous scale and clear current images
        images_prev = images_cur
        images_cur = []

        # Generate num_samples samples in current scale
        #MARIA: REVISED THIS TO GO THROUGH THE RANDOM NOISE SAMPLES GENERATED BY PYRIBS INSTEAD OF GENERATING EACH ONE
        for n in tqdm(range(0, len(in_vecs), 1)):

            # Get noise image
            z_curr = in_vecs[n]
            z_curr = m(z_curr)

            # Set up previous image I_prev
            if (not images_prev) or current_scale == 0:  # if there is no "previous" image
                I_prev = in_s
            else:
                I_prev = images_prev[n]

            I_prev = interpolate(I_prev, [int(round(nzx)), int(round(nzy))], mode='bilinear', align_corners=False)
            I_prev = m(I_prev)

            # We take the optimized noise map Z_opt as an input if we start generating on later scales
            if current_scale < gen_start_scale:
                z_curr = Z_opt

            ###########
            # Generate!
            ###########
            z_in = noise_amp * z_curr + I_prev
            I_curr = G(z_in.detach(), I_prev, temperature=1)

            if current_scale == len(reals) - 1:
                # Convert to ascii level
                level = one_hot_to_ascii_level(I_curr.detach(), token_list)

            # Append current image
            images_cur.append(I_curr)

        # Go to next scale
        current_scale += 1

    print(I_curr.shape())
    return I_curr




if __name__ == '__main__':
    # Parse arguments
    parse = get_arguments()
    parse.add_argument("--out_", help="folder containing generator files", default="output/wandb/latest-run")
    parse.add_argument("--scale_v", type=float, help="vertical scale factor", default=1.0)
    parse.add_argument("--scale_h", type=float, help="horizontal scale factor", default=1.0)
    parse.add_argument("--gen_start_scale", type=int, help="scale to start generating in", default=0)
    #parse.add_argument("--num_samples", type=int, help="number of samples to be generated", default=10)

    opt = parse.parse_args()
    
    archive = GridArchive([1], [(0, 1)])
    #MARIA: PROBLEM WITH SETTING EMITTER SHAPES FOR RANDN VECTORS, BECAUSE WE WILL NEED DIFFERENT SIZES AT EACH DOWNSAMPLE    
    # emitters = [OptimizingEmitter(archive, np.zeros([1,12,8,101]), 0.1)]
    emitters = [
    OptimizingEmitter(
        archive,
        np.zeros(generator.nz),
        0.2,
        batch_size=30,
    ) for _ in range(3)
]

    optimizer = Optimizer(archive, emitters)
    n_iter = 10
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Init game specific inputs
    replace_tokens = {}
    sprite_path = 'mario/sprites'
        
    opt.ImgGen = MarioLevelGen(sprite_path)
    replace_tokens = MARIO_REPLACE_TOKENS
    downsample = special_mario_downsampling

    # Load level
    real = read_level(opt, None, replace_tokens).to(device)
        
    # Load Generator
    generators, noise_maps, reals, noise_amplitudes = load_trained_pyramid(opt)

    # Get input shape for in_s
    real_down = downsample(1, [[opt.scale_v, opt.scale_h]], real, opt.token_list)
    real_down = real_down[0]
    in_s = torch.zeros_like(real_down, device=opt.device)
    prefix = "arbitrary"
        
    for itr in range(3):#(n_iter):
        solutions = optimizer.ask()

        generated_levels = gen_samples(generators, noise_maps, reals, noise_amplitudes, in_vecs=solutions, device = device)


        objectives = solutions
        #bcs = [0]

        #optimizer.tell(objectives, bcs)